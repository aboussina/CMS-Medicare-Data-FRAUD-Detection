{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class Socrata in module sodapy.socrata:\n\nclass Socrata(builtins.object)\n |  Socrata(domain, app_token, username=None, password=None, access_token=None, session_adapter=None, timeout=10)\n |  \n |  The main class that interacts with the SODA API. Sample usage:\n |      from sodapy import Socrata\n |      client = Socrata(\"opendata.socrata.com\", None)\n |  \n |  Methods defined here:\n |  \n |  __enter__(self)\n |      This runs as the with block is set up.\n |  \n |  __exit__(self, exc_type=None, exc_value=None, traceback=None)\n |      This runs at the end of a with block. It simply closes the client.\n |      \n |      Exceptions are propagated forward in the program as usual, and\n |          are not handled here.\n |  \n |  __init__(self, domain, app_token, username=None, password=None, access_token=None, session_adapter=None, timeout=10)\n |      The required arguments are:\n |          domain: the domain you wish you to access\n |          app_token: your Socrata application token\n |      Simple requests are possible without an app_token, though these\n |      requests will be rate-limited.\n |      \n |      For write/update/delete operations or private datasets, the Socrata API\n |      currently supports basic HTTP authentication, which requires these\n |      additional parameters.\n |          username: your Socrata username\n |          password: your Socrata password\n |      \n |      The basic HTTP authentication comes with a deprecation warning, and the\n |      current recommended authentication method is OAuth 2.0. To make\n |      requests on behalf of the user using OAuth 2.0 authentication, follow\n |      the recommended procedure and provide the final access_token to the\n |      client.\n |      \n |      More information about authentication can be found in the official\n |      docs:\n |          http://dev.socrata.com/docs/authentication.html\n |  \n |  close(self)\n |      Close the session.\n |  \n |  create(self, name, **kwargs)\n |      Create a dataset, including the field types. Optionally, specify args such as:\n |          description : description of the dataset\n |          columns : list of columns (see docs/tests for list structure)\n |          category : must exist in /admin/metadata\n |          tags : list of tag strings\n |          row_identifier : field name of primary key\n |          new_backend : whether to create the dataset in the new backend\n |      \n |      WARNING: This api endpoint might be deprecated.\n |  \n |  create_non_data_file(self, params, file_data)\n |      Creates a new file-based dataset with the name provided in the files\n |      tuple.  A valid file input would be:\n |      files = (\n |          {'file': (\"gtfs2\", open('myfile.zip', 'rb'))}\n |      )\n |  \n |  datasets(self, limit=0, offset=0, order=None, **kwargs)\n |      Returns the list of datasets associated with a particular domain.\n |      WARNING: Large limits (>1000) will return megabytes of data,\n |      which can be slow on low-bandwidth networks, and is also a lot of\n |      data to hold in memory.\n |      \n |      This method performs a get request on these type of URLs:\n |      https://data.edmonton.ca/api/catalog/v1\n |      \n |          limit: max number of results to return, default is all (0)\n |          offset: the offset of result set\n |          order: field to sort on, optionally with ' ASC' or ' DESC' suffix\n |          ids: list of dataset IDs to consider\n |          domains: list of additional domains to search\n |          categories: list of categories\n |          tags: list of tags\n |          only: list of logical types to return, among `api`, `calendar`,\n |              `chart`, `datalens`, `dataset`, `federated_href`, `file`,\n |              `filter`, `form`, `href`, `link`, `map`, `measure`, `story`,\n |              `visualization`\n |          shared_to: list of users IDs or team IDs that datasets have to be\n |              shared with, or the string `site` meaning anyone on the domain.\n |              Note that you may only specify yourself or a team that you are\n |              on.\n |              Also note that if you search for assets shared to you, assets\n |              owned by you might be not be returned.\n |          column_names: list of column names that must be present in the\n |              tabular datasets\n |          q: text query that will be used by Elasticsearch to match results\n |          min_should_match: string specifying the number of words from `q`\n |              that should match. Refer to Elasticsearch docs for the format,\n |              the default is '3<60%', meaning that 60% of the terms must\n |              match, or all of them if there are 3 or fewer.\n |          attribution: string specifying the organization datasets must come\n |              from\n |          license: string used to filter on results having a specific license\n |          derived_from: string containing the ID of a dataset that must be a\n |              parent of the result datasets (for example, charts are derived\n |              from a parent dataset)\n |          provenance: string 'official' or 'community'\n |          for_user: string containing a user ID that must own the returned\n |              datasets\n |          visibility: string 'open' or 'internal'\n |          public: boolean indicating that all returned datasets should be\n |              public (True) or private (False)\n |          published: boolean indicating that returned datasets should have\n |              been published (True) or not yet published (False)\n |          approval_status: string 'pending', 'rejected', 'approved',\n |              'not_ready' filtering results by their current status in the\n |              approval pipeline\n |          explicitly_hidden: boolean filtering out datasets that have been\n |              explicitly hidden on a domain (False) or returning only those\n |              (True)\n |          derived: boolean allowing to search only for derived datasets\n |              (True) or only those from which other datasets were derived\n |              (False)\n |  \n |  delete(self, dataset_identifier, row_id=None, content_type='json')\n |      Delete the entire dataset, e.g.\n |          client.delete(\"nimj-3ivp\")\n |      or a single row, e.g.\n |          client.delete(\"nimj-3ivp\", row_id=4)\n |  \n |  download_attachments(self, dataset_identifier, content_type='json', download_dir='~/sodapy_downloads')\n |      Download all of the attachments associated with a dataset. Return the paths of downloaded\n |      files.\n |  \n |  get(self, dataset_identifier, content_type='json', **kwargs)\n |      Read data from the requested resource. Options for content_type are json,\n |      csv, and xml. Optionally, specify a keyword arg to filter results:\n |      \n |          select : the set of columns to be returned, defaults to *\n |          where : filters the rows to be returned, defaults to limit\n |          order : specifies the order of results\n |          group : column to group results on\n |          limit : max number of results to return, defaults to 1000\n |          offset : offset, used for paging. Defaults to 0\n |          q : performs a full text search for a value\n |          query : full SoQL query string, all as one parameter\n |          exclude_system_fields : defaults to true. If set to false, the\n |              response will include system fields (:id, :created_at, and\n |              :updated_at)\n |      \n |      More information about the SoQL parameters can be found at the official\n |      docs:\n |          http://dev.socrata.com/docs/queries.html\n |      \n |      More information about system fields can be found here:\n |          http://dev.socrata.com/docs/system-fields.html\n |  \n |  get_all(self, *args, **kwargs)\n |      Read data from the requested resource, paginating over all results.\n |      Accepts the same arguments as get(). Returns a generator.\n |  \n |  get_metadata(self, dataset_identifier, content_type='json')\n |      Retrieve the metadata for a particular dataset.\n |  \n |  publish(self, dataset_identifier, content_type='json')\n |      The create() method creates a dataset in a \"working copy\" state.\n |      This method publishes it.\n |  \n |  replace(self, dataset_identifier, payload, content_type='json')\n |      Same logic as upsert, but overwrites existing data with the payload\n |      using PUT instead of POST.\n |  \n |  replace_non_data_file(self, dataset_identifier, params, file_data)\n |      Same as create_non_data_file, but replaces a file that already exists in a\n |      file-based dataset.\n |      \n |      WARNING: a table-based dataset cannot be replaced by a file-based dataset.\n |               Use create_non_data_file in order to replace.\n |  \n |  set_permission(self, dataset_identifier, permission='private', content_type='json')\n |      Set a dataset's permissions to private or public\n |      Options are private, public\n |  \n |  update_metadata(self, dataset_identifier, update_fields, content_type='json')\n |      Update the metadata for a particular dataset.\n |          update_fields is a dictionary containing [metadata key:new value] pairs.\n |      \n |      This method performs a full replace for the key:value pairs listed in `update_fields`, and\n |      returns all of the metadata with the updates applied.\n |  \n |  upsert(self, dataset_identifier, payload, content_type='json')\n |      Insert, update or delete data to/from an existing dataset. Currently\n |      supports json and csv file objects. See here for the upsert\n |      documentation:\n |          http://dev.socrata.com/publishers/upsert.html\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  DEFAULT_LIMIT = 1000\n\n"
     ]
    }
   ],
   "source": [
    "help(Socrata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the information from those sections here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "\n",
    "import os\n",
    "socrata_domain = 'data.cms.gov'\n",
    "\n",
    "# Old:\n",
    "socrata_dataset_identifier = 'xbte-dn4t'\n",
    "\n",
    "# New: -AB\n",
    "# socrata_dataset_identifier = 'mhdd-npjx'\n",
    "\n",
    "# App Tokens can be generated by creating an account at https://opendata.socrata.com/signup\n",
    "# Tokens are optional (`None` can be used instead), though requests will be rate limited.\n",
    "#\n",
    "# If you choose to use a token, run the following command on the terminal (or add it to your .bashrc)\n",
    "\n",
    "socrata_token = os.environ.get(\"DxH35RWOHHOtkfUkUERwkSuQJ\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sodapy import Socrata\n",
    "#Part D data : https://data.cms.gov/resource/xbte-dn4t.json\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(socrata_domain, None)\n",
    "\n",
    "# First 2000 results, returned as JSON from API / converted to Python list of\n",
    "# dictionaries by sodapy.\n",
    "Results = client.get(socrata_dataset_identifier, limit = 356226893)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "cmsPartD_df = pd.DataFrame.from_records(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = client.get_metadata(socrata_dataset_identifier)\n",
    "[x['name'] for x in metadata['columns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_amount = [x for x in metadata['columns'] if x['name'] == 'npi'][0]\n",
    "meta_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmsPartD_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python386jvsc74a57bd0617bd25a90f4d494eba9f700175ec3bab28d128b52129a0fdad9d74201035280",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "617bd25a90f4d494eba9f700175ec3bab28d128b52129a0fdad9d74201035280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}